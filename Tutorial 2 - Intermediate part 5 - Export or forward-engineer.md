
# Tutorial 2 - Intermediate part 5 - Export or forward-engineer

[Tutorial 2 - Intermediate part 5 - Export or forward-engineer](https://community.hackolade.com/slides/slide/part-9-export-or-forward-engineer-16?fullscreen=1)

## Unedited transcript of the video

hello everyone and welcome to part nine of our hack related tutorial in this part we're going to be talking about how you can use accolades to export or forward engineer your data models onto different types of structures either file based or instance based or whatever it is that your particular physical data model might want as output right so we'll talk about that right now but first I would like to remind everyone of the fact that Accolade is actually a tool with a purpose right we really want to make it easier for people to understand the data structures that they're dealing with by helping them visualize and graphically Express that in entity relationship diagrams these diagrams just make it easier for humans to understand these data structures they make it easy to design it but also to maintain it and to interact on these data structures with different types of stakeholders both Technical and non-technical stakeholders another thing that you want from a data model is you want it to generate contracts you wanted it to generate schemas that are going to be understood by systems that produce or consume data right so that these systems can understand each other unambiguously during their exchanges and last but not least I think it's also important to remind ourselves of the fact that data models are also useful to feed business facing data dictionaries so that any data citizen in your organization can understand the meaning and the context of the data when they are using it whether it's in some kind of a self-server service in analytics deployment machine learning artificial intelligence whatever the purpose might be right the data model is supposed to make this understanding easier so it is a means to an end and I think it's important to realize that so because it has this purpose and because it is a means to an end Accolade supports what we call forward engineering right this is some kind of an export process where from the data model that you create in Accolade you're going to be able to export this information to a particular schema right a schema for a Target that we support right that we do this through our plugin architecture right we have a plugin for all kinds of different systems and these systems could be you know servers instances but there could also be schema Registries or just plain old files on your local machine or on some network drive we also want to be including not just the data model in there but also the the configuration of those physical systems in some way right like the constraints that we want to put in place or the indexing that we want to activate right so obviously there are significant roles and rights uh review considerations here you don't want everyone to be able to do forward engineering on production systems for example or you might want to consider you know separating the different uh roles in your organization and um have for example the output be some kind of a file that could be picked up in some Downstream process for application to your tests or even production systems later on when it comes to exporting or forward engineering to files you see here what the different file formats might be right so it could either be a Json or yaml sample document it could be a schema or a yaml schema a Json schema or yaml schema but we also have you know an Excel file that you can use to for example perform built updates on data models right so we use Excel as a mechanism to let people very easily and and productively edit large numbers of data models automatically or manually we also allow you to generate an API file a model driven API file as we call it based on the Swagger or open API specifications and then of course you know we not only support that on your local system but we allow you to do that also to your git enabled system right so that means that you will have on your local machine a git enabled directory that synchronizes with your shared repos and therefore you will for example trigger some kind of a CI CD workflow last but not least I'd like to mention that Accolade is also supporting the end-to-end integration with data dictionaries right so for example calibra that's probably the only one that we currently support but there's a live and real-time integration with a data dictionary like Libra and we are constantly evaluating and investigating other potential targets for us to integrate with as data dictionaries so let's show you how this might work right so we'll jump into our hacklight environment right here I have a sample data model here which is based on the famous Northwind data model and what I'd like to show you here is how you can for example forward engineer this into a file based format but also how you can do that into instance based systems so let's see how that works right so here at the top you have a forward engineering button right so here I can say okay please forward engineer that to a particular location in my file system right I would like you to forward engineer everything right you can say which specification you want to use whether or not you want to reference definitions or resolve them right and you can also specify how to do that specifically when you do that it will ask you for a particular location for you to put this in and here I will just put this in a local directory here and this will be exported then right so that's a very very easy very easy to do you can do this in all these these different formats and and all of these different options that you might have um all of this is available for you to configure now let me also show you how you can apply this to an instance right and again this is always going to be Target specific plugin specific right it depends on the plugin that you are using if you're using a mongodb plugin like I am right here or if you're using a relational plugin for postgres or if you're using an Avro schema Plugin or whatever it is that you're using your forward engineering options are going to be a little bit specific to that environment you can access this in different ways right so here if I go here and I say okay I would like you to generate that mongodb script right so then this is going to be exported you can say okay I want you to generate a an update script or you know include sample data you know you can have a number of configurations here or you can also go through this little tab over here and just immediately apply this to your mongodb instance if you've got that configured obviously right so I've generated this here and I'm going to apply this script over there and I'm going to say okay which connection do you want to use right so this is a connection to a centrally hosted Atlas database connect to it and a few seconds later the script has been applied right let me show you that for one second here and here you can see this right so this is a compass the atlas or mongodb tool that we use for managing data stores right so here you see all of the different entities that I had in my uh data model here in the ER diagram now let me show you something a little bit more advanced right so if I would say for example here on the customers collection I want to add some indexes right so let me call this a new Index right and I say okay which key do you want to use for that let's call it the company name right then I save that and the mongodb script will now be updated note that if I go to Compass here on the customer's entity there is an indexes Tab and there is only a an index on the internal ID right so not on the property that I just selected which was the company name property right but if I now apply this apply this script to my Atlas instance right then you will see that if I now refresh this that there is a new index that was created right so again you can do all kinds of advanced things here with our forward engineering capability I hope this was a useful uh overview and obviously there's lots of things that you can additionally do here like for example you can do all of the capabilities that we just demonstrated here not just through the UI but you can also do it through the command line interface for example from a Docker container right so but all of that is available to you to make your data modeling even more productive so with that I'm going to wrap up this part of our tutorial and I invite you to read more on it on our documentation our Blog the Fantastic mongodb data modeling and schema design book or you know any other online resource that you might fancy I thank you for your attention and I wish you a wonderful rest of your day