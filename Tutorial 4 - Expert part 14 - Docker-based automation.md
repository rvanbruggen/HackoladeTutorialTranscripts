
# Tutorial 4 - Expert part 14 - Docker-based automation

[Tutorial 4 - Expert part 14 - Docker-based automation](https://community.hackolade.com/slides/slide/docker-based-automation-57?fullscreen=1)

## Unedited transcript of the video

hello everyone and welcome to this hack tutorial today we'll be talking about our Docker based data modeling automation possibilities using the hack CLI that we're going to be deploying inside a Docker container before we do that let's have a little context the first thing that you should really understand is that this is something that we want to facilitate because we believe in the power of integrating the entire data modeling life cycle with devops applications the infinite Loop that you see here which many people know very well from their agile software engineering and devop cicd integration storylines is something that we believe should be applied to data modeling professions as well as it enables so many different new ways of doing things we believe that in a agile and devops oriented context data modeling has a true possibility to be as relevant as it ever was and that you know both are the physical data modeling capabilities uh and you know all kinds of iterative optimizations and evolutions compliance governance capabilities are going to be enabled by doing this in a structured fashion we call this metadata as code you know that's our tagline to make people understand what this is all about and obviously this is greatly enabled by our git Centric repository strategy right so haate doesn't have its own proprietary repository for data models so we always rely on git to provide us with many of those really interesting capabilities in terms of versioning model comparisons but also lots of automation capabilities why because git obviously because of its nature because of how it was developed has been integrated very very tightly with all kinds of devops continuous integration and continuous deployment pipelines this is part and parcel of what people are doing using Git infrastructures it has been integrated with these continuous integration and continuous deployment pipelines this is what we would like to enable for data modeling as well right so that when you have individuals that are contributing new artifacts to their data models in their local repost well as soon as they push these things into the central uh remote right into the git remote then automatically there will be a number of steps taken using a command line interface that allow you to basically not have to worry about it anymore it will just run automatically the CLI will take care of this and eventually you know all the consumers of the data models will receive what they need to receive based on the work of all of those individuals working in their local repos but it will flow automatically through the entire pipeline that obviously doesn't work as well if we're always working on a local machine on someone's individual workstation in order to make these automations work and that's why we have introduced this Docker based automation so that it can actually run on a centralized piece of infrastructure on a Docker uh infrastructure that allows you to run these pipelines automatically over there without having to worry about you know the individual being online yes or no we believe that there's actually two use cases primary use cases for this type of integration work first one is um governance first use cases where um we actually start from the evolution of a data model the data model is evolving and is pushed and is approved into the repository which then generates some kind of reverse engineering capability to see what currently inside a database instance and then we compare this to uh what we have recently then approved and create a formalization of the difference which we call a Delta model based on the difference between what we have just approved and what we have in production we can generate this alter script that is then forward engineered um so that um a DBA can review it before they apply the first five steps here can all be automated as soon as the um IND individual data modeler pushes the button and releases the new version of the model all of the reverse engineering can be done automatically the comparison can beo done automatically the Delta model generation can be done automatically the alter script generation can be done automatically it's just the review and the application of the alter script that then would have to be done manually so you can see that there's a huge amount of work that can be saved by doing this in a Docker container and this uh will help us with our governance first use case the Second Use case is where we have some kind of a code first uh circumstance or use case right where the developers you know because they need some new piece of functionality and they're coding this uh inside their development environment they actually make some changes to the database schema now that database schema Evolution would automatically trigger the command line interface and force a reverse engineering of that database instance into a new version of the uh database model which we can then compare to to the originally agreed or documented version of the model right and see you know what's currently in production right the database schema that is currently in production how does it compare to what we have agreed to and then we can say okay maybe we need to review those changes and potentially merge that into the Baseline model as you can see here all of the first three steps can be done automatically right we can trigger the CLI and reverse engineer from the database instance compare it to the documented model and then there's obviously a manual step where someone needs to go through the changes and review them and potentially then again merge the changes into the Baseline model automatically using the docker container so the principle here is always the same you know there's some kind of event that triggers actions right something happens a commit happens or a schema change happens or something like that and then you have Runners that run jobs there's a workflow capability inside many of these cicd infrastructures that allows you to automate the runners that follow from the events so so there's lots of things that you can do uh we have a lot of documentation on this and obviously in this tutorial we will go through some of these um in quite a bit of detail the scenarios that we'll be going through are the following right so first we'll reverse engineer a database you know we'll simulate that to be done overnight then we will compare that reverse engineered model with a baseline model and generate a Delta model that formalizes the difference between the two um and then you know we won't be doing the review and everything but you know you can probably understand that this can then um be taken forward from there on as well we'll also just quickly simulate you know the generation of documentation in HTML and PDF formats uh for a particular model right so there's a new version of the model then obviously the documentation should be updated as well so let's dig right in and uh show you how this is done all right let's uh dig right in um here we are in our manual page over here right so in the online user manual search for Docker right Docker container and this will lead you to a specific um page that is actually not on our website but on uh GitHub right so this is actually this page I had it open here already and what we want to do now first is we actually want to clone this repo right so the holade docker repo we want to clone that to our local machine so I'm going to copy this right and then I'm going to go to my haate client over here and I'm going to say well why don't we uh clone this particular repo from a particular URL right so this is it let's clone it right and then we'll put it over here in a new folder called Docker clone right create that new folder open that folder and then uh hackl will actually pull from the central repo the files that I need I can show you this over here right so now I've got the docker clone repo and I have this particular directory structure that has been added to my local file system this is important I I'm actually going to open up a terminal in this in this uh folder right because we will be using using that a lot right we will be running the docker uh based command line interface from our terminal and I will leave it to you to imagine that this is how you would trigger it from one of your cicd pipelines all right so uh we're going to go into the instructions over here right so we are going to go into this uh folder over here and here you see all the instructions that you need in order to actually start working with this right so the first thing that we want to do is we want to build the uh image with the normal defaults install there's a bunch of options that you could have here as well but what I'm going to do is I'm actually going to go into my terminal here and see where I am I'm in the right directory and I'm going to build the image from scratch in my local directory right so this is going to take a while so I'll pause this for a second I'll reactivate it a little bit here because then you can see that things are actually being um installed here on my local file system but you don't need to wait for all of this so I'll just pause it again and here we are um the install has been uh finished on my local file system now when you look at that the file system over here you see a couple of files that are really important uh more specifically this yaml file over here that you can open with Visual Studio or with an alternative text editor but what you see here is you know a couple of um informations about the uh CLI and the version of the CLI but specifically also the mapping of the directories right so the directories of your Docker container are going to get mapped to specific directories on your local file system and you will see those uh come up here a little bit later on by the way all of this is explained over here as well right so you can see this over here the instructions are very very clear and just to verify if we've actually been able to install the holade studio CLI correctly we're going to run this little command here and go to our terminal and run it over there and then hopefully this will come back and say well hey here's your help uh instructions for the hack Studio CLI and that will kind of prove that the installation has been successful takes a little bit of time but you know this is now running appropriately you'll see it pop up in a second here and it will show you the um help instructions that you would also normally get from your CLI installation it's important to understand that this CLI is now no longer running on your local machine it's actually running on your Docker container now a very important step that you always need to take is you actually need to validate the haate license on this uh Docker container installation and the way to do that is a little bit um uh particular you first need to get a handle of the unique identifier uh and you do that by running this particular Command right it will show you the computer ID of the docker container in which accolate has been installed and then the next thing that we do is we're going to run this particular Command right validate key and we need the concurrent license key for this as well so I should really make sure that I have have everything right so I'm going to go to my terminal again and I'm going to add my uh uh license key to this Command right I'll do that right there right and then I also need to grab the rest of the instruction which is that I'm going to add this thing here plus the identifier right so and the identifier is this thing over there right that I'm going to copy and paste over there and when I run this this will actually make the uh Docker container uh which is effectively kind of like a separate machine it will validate the license um with the hack licensing server and make sure that uh you can actually use the software within the hack Lade container this shouldn't take uh very long um once it has been completed it says that the license key has been successfully activated and that means that we can proceeded note that there's a lot of instructions here for offline activation many Docker containers are actually not connected to the internet so therefore you would want to be able to do this offline all these things are well described over here but what we're going to do now is we're going to switch to a different article over here where we're going to through go through a couple of scenarios right we're going to go through a couple of scenarios that are described in this article and you know couple of things that are quite important if you're on the Mac right so don't use the V virtualization framework for example but this is quite specific but here we're going to go through some examples scenarios and so let's start right the first thing that we're going to do is we're actually going to make sure that our Docker container has the possibility to do reverse engineering of a mongodb atlas um instance and to do that what we're going to do is I'm going to switch to my um haate full installation over here and I'm going to show you that I'm going to um use the same connection capability that I have over here and I'm going to export that in an encrypted way to this Docker clone repo I'm going to add a uh folder here right mongodb Atlas and I'm going to save this connection information over there why because now my Docker container can actually use that connectivity that I've already preconfigured in the visual environment of hack Studio it can actually use this in our Docker container as well you will notice that now over here I have a mongodb at folder that has been added it's actually been added in the wrong location it should be over there right so um switching that around a little bit here so but now it's in the right location in mongodb Atlas And there's the bin file that my Docker container will be able to use right so that's the first thing that we need to do we need that uh connectivity file and now we're ready to actually do a first reverse engineering run and we do that by um running this command over here let me just show it to you over here in my terminal I'll paste it over here this is the dock compose where I'm doing the reverse engineering of a mongodb using a connect file right that's the file that I just added to my mongodb Atlas directory and then we're going to create a new model right and that model is going to be called uh Docker Revenge mongodb Atlas mx. hk. Json and I'm going to do this for the sample mflix database on the atlas infrastructure so let's uh do this we'll run the uh reverse engineering inside the docker container and again this is going to take a few seconds so I'll pause it for a while and come back to you in a second and after a couple of seconds you will see that the model has actually been saved right so if I go back over here now I will see that in the same directory I now have this model that was added let's open that let's open it in holade without saving right I'll go over here in the data directory mongodb Atlas this is the model that we just created in our Docker container and here we are right so this is all set right we have the model that was uh generated in our Docker container and now what we'll do is actually we'll go uh one step further what I'm going to do over here is I'm actually going to take an intermediate step and use mongodb Compass to make a change to the model right so let's see here I'm in compass over here this is sample mflix and what I'd like to do here is I'm going to create create a collection inside sample mflix which is called animals and inside animals I'm going to add some data and that data is actually going to be like this name is dog right so I've added a first document I'm going to copy that document and paste it and say cat I'm going to do the same thing and I'll make it a snake so I have three documents in this collection now in the the sample implex animals collection why am I doing this because if I now go back and I rerun the u reverse engineering task right and create a second model right so imagine what has happened here right so someone has actually gone into our Atlas database and has modified the schema of that database so we now want to uh do another reverse engineering and paste this uh and create a V2 of the model right so the second version of the model that we're going to create by doing the reverse engineering in our doc do Docker container and therefore hopefully it will detect that this new collection has been added to the mongodb database again this is going to take a few seconds so let's uh pause it and here we are the model has been saved let's see if we can find it quite easily yeah here we go right V2 has been saved over there right and I can go into my hack a studio and see if I can open it up I should be able to open it up right that's the second model and here we are right the animals collection has been added to the model it actually worked and therefore our next step is is really really easy I'm going to compare these two reverse engineered models in our Docker container right so we have two versions of the model we have them right here these two and we're going to instruct our Docker container to compare these we paste the command right so we have a comp mod command with model one over there model two over there and we are going to generate a Delta model the Delta model being the formalization of the difference between the two models and hopefully the Delta model will show us that now we actually have an additional collection that was added to the mongod DP database let's see if this is going to work normally this is going to go a little bit faster and it's going to generate this U Delta model for us um should go quite fast let's see right yeah here we go right so this is the Delta model let's see if we can open that up open the model in our data directory and this is the Delta model and the Delta model indeed does specify that there was an animals entity added to the model so again pointing you back to how you could integrate this into a pipeline so we have a model we detect the schema change we generate another model reverse engineer another model We compare those models generate a Delta model all of this is done automatically with these few simple commands inside our Docker container there's a couple of other things that you can do obviously like for example generate documentation right so I'll uh very quickly show you how you can generate documentation using the uh Docker container right so here we go uh this is the command right so it's it's always the same structure this one says gen do from that mongodb model that we reverse engineered reverse engineered originally and we're going to generate a PDF right which we will put in the same location we have another one over here um that does the same thing which is it generates the HTML documentation and we can actually try and run that in parallel so we now are spinning up two Docker containers in parallel multi-threaded so to speak and one is generating the PDF and the other one is generating the HTML we will see both of them pop up uh inside this directory very soon hopefully this will finish quite quickly and then you can just see how this works and how you can automate the documentation generation task simply by running this automatically as part of your pipeline inside a Docker container oh here we go this one is finished the doc the PDF um generation has finished here we see it right this is the PDF that was generated and let's see if the other one is also almost ready the HTML has also been generated so therefore that should also be present inside this directory here we go so that's it um this uh hopefully wraps it up and makes it clear how you can use the um Docker container infrastructure to automate your cicd pipelines to collocate your data inside git uh using accolate Studio and then basically save a whole bunch of time by automating these things inside a pipeline both GitHub Azure bitbucket gitlab they all have their own ways of doing this and of triggering your uh Docker infrastructure um and hopefully that is something that you can take a look at yourself that's it for the demo I'd like to finish this uh tutorial by pointing you to some really cool reading materials we obviously have our documentation we have the blog we have the social media Pages we obviously want you to try the product for free I would also like to highlight the fact that there's a large number of actual great books that are available about these topics uh mongodb was the first but as you will see there's really great books around NJ data modeling Oracle 23c elastic search and we have more coming very very soon all of these books are built around the use of holade for their data modeling exercises and you will no doubt recognize many of the capabilities there so that wraps up our tutorial and if you have any questions please reach out and other than that I'm going to wish you a wonderful rest of your day